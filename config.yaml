random_state: 42

dataset:
  train_path: 'data/split/train.csv'
  val_path : 'data/split/val.csv'
  train_val_path: 'data/split/trainval.csv'
  test_path: 'data/split/test.csv'
  zero_weight: 1
  one_weight: 1
  target_rec: 0.9
  target_prc: 0.9
  eval_target: 'recall'


preprocessing:
    data_choice: 2 
    is_scaling: True
    scaler_option: 1
    sample_option: 2
    over_factor: 80
    under_factor: 80
    over_strategy: 'smote'
    k_neig: 3
    remove_dublicates: True
    remove_outlier: False
    change_time: True
    train_val: True




model:

  random_forest_params:
    params: 
      n_estimators: 50
      max_depth: 9
      random_state : 42

  logistic_regression:
    params:
      fit_intercept: True
      solver: 'sag'
      max_iter: 10000
      random_state : 42

  voting_classifier:
    params:
      model1:
        solver: 'sag'
        fit_intercept: True
        max_iter: 10000
        random_state : 42

      model2:
        max_depth: 9
        n_estimators: 50
        random_state : 42
      voting: 'hard'
      

  xgboost:
    params:
      max_depth: 3
      lr: 0.2
      n_estimators: 100
      random_state : 42

  light_boost:
    params:
      n_estimators: 500
      lr: 0.05
      max_depth: 3
      random_state : 42

  cat_boost:
    params:
      depth: 3
      iterations: 100
      lr: 0.1
      random_state : 42

  knn:
    params:
      n_neighbours: 60
      apply_pca: False
      apply_kmeans: False
      n_components: 4
      neg_samples: 405
